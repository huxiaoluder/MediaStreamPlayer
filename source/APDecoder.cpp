//
//  APDecoder.cpp
//  MediaStreamPlayer
//
//  Created by xiaoming on 2018/12/26.
//  Copyright Â© 2018 freecoder. All rights reserved.
//

#include "APDecoder.hpp"

using namespace MS;
using namespace MS::APhard;

void
APDecoder::decodeVideo(const MSMedia<MSEncodeMedia> * const videoData) {
    const MSMedia<MSEncodeMedia> &data = *videoData;
    ReGetContext: APCodecContext * const decoderContext = getVideoDecoderContext(data);
    
    if (decoderContext) {
        OSStatus status = noErr;
        
        assert(*(uint32_t *)data.naluData == 0x01000000);
        
        const MSNaluParts &naluParts = data.getNaluParts();
        
        // å¸§æ•°æ®å¼•ç”¨
        uint32_t *tempRef = (uint32_t *)naluParts.dataRef();
        // å¸§æ•°æ®é•¿åº¦
        size_t tempSize = naluParts.dataSize();
        // åŒ…å«å¼€å§‹ç 
        tempRef -= 1;
        
        // atom åž‹: æ›¿æ¢å¼€å§‹ç ä¸ºæ•°æ®é•¿åº¦(å°ç«¯å­˜å‚¨)
        *tempRef = getReverse4Bytes((uint32_t)tempSize);
        
        // atom åž‹: nalu æ•°æ®é•¿åº¦
        tempSize += 4;
        
        CMBlockBufferRef blockBuffer = nullptr;
        status = CMBlockBufferCreateWithMemoryBlock(kCFAllocatorDefault,
                                                    tempRef,
                                                    tempSize,
                                                    blockAllocator, // ä¼ å…¥ nullptr, å°†ä½¿ç”¨é»˜è®¤åˆ†é…å™¨ kCFAllocatorDefault.
                                                    nullptr, // è¯¥ç»“æž„å‚æ•°å°†è‡ªå®šä¹‰å†…å­˜çš„åˆ†é…å’Œé‡Šæ”¾, å¦‚æžœä¸ä¸º nullptr, blockAllocator å‚æ•°å°†è¢«å¿½ç•¥
                                                    0,
                                                    tempSize,
                                                    bufferFlags, // ä¼ å…¥ NULL åˆ™è¯¥å‡½æ•°ä¸ä¼šå¯¹ä¼ å…¥æ•°æ®é‡æ–°åˆ†é…ç©ºé—´.
                                                    &blockBuffer);
        if (status != kCMBlockBufferNoErr) {
            OSStatusErrorLocationLog("call CMBlockBufferCreateWithMemoryBlock fail",status);
            delete videoData;
            return;
        }
       
        CMSampleBufferRef sampleBuffer = nullptr;
        size_t sampleSizeArray[] = {tempSize};
        
        /*
         // æ³¨: æ—¶é—´ä¿¡æ¯é™„å¸¦å‚æ•°(å¯¹è§£ç å™¨å¹¶æ²¡æœ‰å½±å“), è¿™é‡Œå› ä¸ºè‡ªå®šä¹‰é€ä¼ ä¿¡æ¯ APVideoAttachment ä¸­é™„å¸¦äº†æœ‰æ•ˆæ•°æ®, æ‰€ä»¥ä¸ç”¨ä¼ è¾“
         CMSampleTimingInfo sampleTimingArray[] = {{
            .presentationTimeStamp = {
                .value = 1,
                .timescale = videoParametersMap[this]->frameRate,
                .flags = kCMTimeFlags_Valid,
                .epoch = 0,
            },
            .duration = NULL,
            .decodeTimeStamp = NULL
         }};
         */
        
        // æŠ¥: kVTVideoDecoderMalfunctionErr -12911,
        // API ä¸­(CM_NULLABLE formatDescription)  å¹¶ä¸å‡†ç¡®. --------------------------------Â¬
        status = CMSampleBufferCreateReady(kCFAllocatorDefault,                      //   Â¦
                                           blockBuffer,                              //   â†“
                                           decoderContext->getVideoFmtDescription(), // å¿…é¡»ä¼ (ç”¨äºŽæè¿°blockBuffer),å¦åˆ™å›žè°ƒæŠ¥é”™,ä¸”ä¼šå¡æ­»è§£ç å‡½æ•°
                                           sizeof(sampleSizeArray) / sizeof(size_t),
                                           0, // sizeof(sampleTimingArray) / sizeof(CMSampleTimingInfo),
                                           nullptr, // sampleTimingArray,
                                           sizeof(sampleSizeArray) / sizeof(size_t),
                                           sampleSizeArray,
                                           &sampleBuffer);
        if (status) {
            OSStatusErrorLocationLog("call CMSampleBufferCreateReady fail",status);
            CFRelease(blockBuffer);
            delete videoData;
            return;
        }

        videoAttachment.videoSource = videoData;
        videoAttachment.videoParameters = videoParametersMap[this];
        
        // VTDecodeInfoFlags infoFlagsOut = NULL;
        status = VTDecompressionSessionDecodeFrame(decoderContext->videoDecoderSession,
                                                   sampleBuffer,
                                                   decodeFlags, // ä¼ å…¥ NULL åˆ™è¯¥å‡½æ•°ä¼šé˜»å¡žåˆ°å›žè°ƒå‡½æ•°è¿”å›žåŽæ‰è¿”å›ž.(API æ³¨é‡Šæœ‰è¯¯ 0 ä¸ºåŒæ­¥)
                                                   &videoAttachment, // é™„å¸¦å‚æ•°, ä¼šé€ä¼ åˆ°å›žè°ƒå‡½æ•°
                                                   nullptr);
        CFRelease(sampleBuffer);
        CFRelease(blockBuffer);
        if (status != noErr) {
            OSStatusErrorLocationLog("call VTDecompressionSessionDecodeFrame fail",status);
            if (status == kVTInvalidSessionErr || // APPè¿›å…¥åŽå°æ—¶, ç³»ç»Ÿä¼šé‡ç½®è§£ç å™¨
                status == kVTFormatDescriptionChangeNotSupportedErr) { // sps, pps å˜åŒ–è·¨åº¦å¤ªå¤§
                delete decoderContexts[videoData->codecID];
                decoderContexts.erase(videoData->codecID);
            }
            goto ReGetContext;
        }
    } else {
        delete videoData;
    }
}

void
APDecoder::decodeAudio(const MSMedia<MSEncodeMedia> * const audioData) {
    const MSMedia<MSEncodeMedia> &data = *audioData;
    APCodecContext * const decoderContext = getAudioDecoderContext(data);
    
    if (decoderContext) {
        OSStatus status = noErr;
        
        const MSAudioParameters &audioParameters = *audioParametersMap[this];
        
        AudioConverterComplexInputDataProc decompressionInputProc = nullptr;
        UInt32 outPacktNumber = 0;
        switch (audioData->codecID) {
            case MSCodecID_AAC: {
                outPacktNumber = AacPacketFrameNum;
                decompressionInputProc = decompressionAacConverterInputProc;
            }   break;
            case MSCodecID_ALAW: {
                outPacktNumber = AlawPacketFrameNum;
                decompressionInputProc = decompressionAlawConverterInputProc;
            }   break;
            case MSCodecID_OPUS: {
                outPacktNumber = 0;
                decompressionInputProc = decompressionOpusConverterInputProc;
            }   break;
            default: {
                delete audioData;
            }   return;
        }
        
        UInt32 mDataByteSize = outPacktNumber * 2 * (UInt32)audioParameters.channels;
        AudioBufferList outBufferList {
            .mNumberBuffers = 1,
            .mBuffers[0] = {
                .mNumberChannels = (UInt32)audioParameters.channels,
                .mDataByteSize = mDataByteSize,
                .mData = malloc(mDataByteSize)
            }
        };
        
        audioAttachment.audioSource = audioData;
        audioAttachment.audioParameters = &audioParameters;
        
//        static AudioStreamPacketDescription outAspDesc[1024];
        status = AudioConverterFillComplexBuffer(decoderContext->audioDecoderConvert,
                                                 decompressionInputProc,
                                                 &audioAttachment,
                                                 &outPacktNumber,
                                                 &outBufferList,
                                                 nullptr); //outAspDesc
        if (status != noErr) {
            OSStatusErrorLocationLog("call AudioConverterFillComplexBuffer fail",status);
            delete audioData;
            return;
        }
        
        AudioBuffer *audioBuffer = new AudioBuffer();
        *audioBuffer = outBufferList.mBuffers[0];
        
        APFrame *frame = new APFrame(audioBuffer, audioParameters);
        
        MSTimeInterval timeInterval{(int)outPacktNumber, audioParametersMap[this]->frequency.value};
        
        launchAudioFrameData(new APDecoderOutputMeida(frame,
                                                      timeInterval,
                                                      audioData,
                                                      APFrame::freeAudioFrame,
                                                      APFrame::copyAudioFrame));
    } else {
        delete audioData;
    }
}

map<APDecoder *, const MSVideoParameters *>
APDecoder::videoParametersMap;

map<APDecoder *, const MSAudioParameters *>
APDecoder::audioParametersMap;

APDecoder::APDecoder(const VTDecodeFrameFlags decodeFlags)
:APDecoderProtocol((void *)decompressionOutputCallback),
decodeFlags(decodeFlags),
bufferFlags(initBufferFlags()),
blockAllocator(initBlockAllocator()) {

}

APDecoder::~APDecoder() {
    auto mediaParameters = videoParametersMap[this];
    if (mediaParameters) {
        videoParametersMap.erase(this);
        delete mediaParameters;
    }
    for (auto element : decoderContexts) {
        delete element.second;
    }
    decoderContexts.clear();
}

const MSVideoParameters *
APDecoder::getCurrentVideoParameters() {
    return videoParametersMap[this];
}

const MSAudioParameters *
APDecoder::getCurrentAudioParameters() {
    return audioParametersMap[this];
}

CMBlockBufferFlags
APDecoder::initBufferFlags() {
    if (decodeFlags) {
        return kCMBlockBufferAssureMemoryNowFlag;
    }
    return NULL;
}

CFAllocatorRef
APDecoder::initBlockAllocator() {
    if (bufferFlags) {
        return kCFAllocatorDefault;
    }
    return kCFAllocatorNull;
}

APCodecContext *
APDecoder::getVideoDecoderContext(const MSMedia<MSEncodeMedia> &sourceData) {
    MSCodecID codecID = sourceData.codecID;
    APCodecContext *decoderContext = decoderContexts[codecID];
    
    if (sourceData.isKeyFrame) {
        const MSNaluParts &naluParts = sourceData.getNaluParts();
        // è§£æž sps åŸºæœ¬ä¿¡æ¯(å®žæ—¶æ›´æ–°å®½é«˜å¸§çŽ‡è‰²åŸŸ)
        const MSVideoParameters *videoParameter = videoParametersMap[this];
        if (videoParameter) {
            delete videoParameter;
        }
        if (codecID == MSCodecID_H264) {
            videoParameter = naluParts.parseH264Sps();
        } else {
            videoParameter = naluParts.parseH265Sps();
        }
        videoParametersMap[this] = videoParameter;
        
        if (decoderContext) {
            // æ£€æµ‹å½“å‰è§£ç å™¨é…ç½®æ˜¯å¦èƒ½è§£ç è¯¥æ•°æ®å¸§(sps, pps è¢«æ”¹å˜)
            bool ret = decoderContext->canAcceptNewFormatDescription(naluParts);
            /** é‡ç‚¹(å¤§å‘, ç³»ç»Ÿ Bug):
             æŸäº›æœºåž‹åœ¨è§£ç å‰, æ£€æµ‹åˆ°å‚æ•°å˜åŒ–è¿‡å¤§æ—¶, ä¸èƒ½å¤Ÿç»§ç»­è®©è§£ç å™¨è§£ç è¯¥æ•°æ®, è‹¥ç»§ç»­è§£ç , æŠ¥é”™: -12916 åŽ,
             ä¼šå¯¼è‡´å½“å‰è§£ç å™¨æ— æ³•é‡Šæ”¾, å› ä¸ºåœ¨é”€æ¯è§£ç å™¨æ—¶:
             VTDecompressionSessionWaitForAsynchronousFrames() å’Œ VTDecompressionSessionInvalidate()
             ä¸¤ä¸ªå‡½æ•°å†…éƒ¨éƒ½ä¼šé”æ­», æ‰€ä»¥åº”è¯¥ç›´æŽ¥é”€æ¯å½“å‰è§£ç å™¨å¹¶åˆå§‹åŒ–iæ–°çš„è§£ç å™¨
             */                                                // â¬
            if (!ret) { // sps, pps å˜åŒ–è·¨åº¦å¤ªå¤§ð—…                    â¬
                delete decoderContext;                         // â¬
                decoderContext = new APCodecContext(codecID, videoParameter->isColorFullRange, naluParts, *this);
                decoderContexts[codecID] = decoderContext;
            }
        } else {
            decoderContext = new APCodecContext(codecID, videoParameter->isColorFullRange, naluParts, *this);
            decoderContexts[codecID] = decoderContext;
        }
    }
    return decoderContext;
}

APCodecContext *
APDecoder::getAudioDecoderContext(const MSMedia<MSEncodeMedia> &sourceData) {
    MSCodecID codecID = sourceData.codecID;
    APCodecContext *decoderContext = decoderContexts[codecID];
    
    if (!decoderContext) {
        const MSNaluParts &naluParts = sourceData.getNaluParts();
        // éŸ³é¢‘ä¸€èˆ¬ä¸ä¼šåŠ¨æ€æ›´æ”¹ç¼–ç é…ç½®, æš‚æ—¶ä»¥é¦–æ¬¡çš„ adts æ•°æ®ä¸ºå‡†
        const MSAudioParameters *audioParameters = nullptr;
        switch (codecID) {
            case MSCodecID_AAC: {
                 audioParameters = naluParts.parseAacAdts();
            }   break;
            case MSCodecID_ALAW: {
                auto audioParam = new MSAudioParameters;
                audioParam->profile     = 1;
                audioParam->channels    = 1;
                audioParam->frequency   = {11, 8000};
                audioParameters = audioParam;
            }   break;
            case MSCodecID_OPUS: {
                //TODO: MSCodecID_OPUS
            }   return nullptr;
            default: return nullptr;
        }
        audioParametersMap[this] = audioParameters;
        decoderContext = new APCodecContext(codecID, *audioParameters, *this);
        decoderContexts[codecID] = decoderContext;
    }
    return decoderContext;
}

void
APDecoder::decompressionOutputCallback(void * MSNullable decompressionOutputRefCon,
                                       void * MSNullable sourceFrameRefCon,
                                       OSStatus status,
                                       VTDecodeInfoFlags infoFlags,
                                       CVImageBufferRef MSNullable imageBuffer,
                                       CMTime presentationTimeStamp,
                                       CMTime presentationDuration) {
    if (status == noErr && imageBuffer) {
        const APAsynDataProvider &dataProvider = *(APAsynDataProvider *)decompressionOutputRefCon;
        const APVideoAttachment  &attachment = *(APVideoAttachment *)sourceFrameRefCon;

        APFrame *frame = new APFrame(CVPixelBufferRetain(imageBuffer), *attachment.videoParameters);
        
        MSTimeInterval timeInterval{1, attachment.videoParameters->frameRate};
        
        dataProvider.launchVideoFrameData(new APDecoderOutputMeida(frame,
                                                                   timeInterval,
                                                                   attachment.videoSource,
                                                                   APFrame::freeVideoFrame,
                                                                   APFrame::copyVideoFrame));
        
    } else {
        OSStatusErrorLocationLog("APDecoder decode video error!", status);
    }
};

OSStatus
APDecoder::decompressionAacConverterInputProc(AudioConverterRef MSNonnull inAudioConverter,
                                              UInt32 * MSNonnull ioNumberDataPackets,
                                              AudioBufferList * MSNonnull ioData,
                                              AudioStreamPacketDescription * MSNullable * MSNullable outDataPacketDescription,
                                              void * MSNullable inUserData) {
    const APAudioAttachment &audioAttachment = *(APAudioAttachment *)inUserData;
    const MSNaluParts &naluParts = audioAttachment.audioSource->getNaluParts();
    
    ioData->mNumberBuffers = 1;
    ioData->mBuffers->mData = (void *)naluParts.dataRef();
    ioData->mBuffers->mDataByteSize = (UInt32)naluParts.dataSize();
    ioData->mBuffers->mNumberChannels = (UInt32)audioAttachment.audioParameters->channels;
    
    static AudioStreamPacketDescription aspDesc;
    aspDesc.mStartOffset = 0;
    aspDesc.mVariableFramesInPacket = 0;
    aspDesc.mDataByteSize = (UInt32)naluParts.dataSize();
    *outDataPacketDescription = &aspDesc;
    
    return noErr;
}

OSStatus
APDecoder::decompressionAlawConverterInputProc(AudioConverterRef MSNonnull inAudioConverter,
                                               UInt32 * MSNonnull ioNumberDataPackets,
                                               AudioBufferList * MSNonnull ioData,
                                               AudioStreamPacketDescription * MSNullable * MSNullable outDataPacketDescription,
                                               void * MSNullable inUserData) {
    const APAudioAttachment &audioAttachment = *(APAudioAttachment *)inUserData;
    auto audioSource = audioAttachment.audioSource;
    
    ioData->mNumberBuffers = 1;
    ioData->mBuffers->mData = (void *)audioSource->naluData;
    ioData->mBuffers->mDataByteSize = (UInt32)audioSource->naluSize;
    ioData->mBuffers->mNumberChannels = (UInt32)audioAttachment.audioParameters->channels;
    
    return noErr;
}


OSStatus
APDecoder::decompressionOpusConverterInputProc(AudioConverterRef MSNonnull inAudioConverter,
                                               UInt32 * MSNonnull ioNumberDataPackets,
                                               AudioBufferList * MSNonnull ioData,
                                               AudioStreamPacketDescription * MSNullable * MSNullable outDataPacketDescription,
                                               void * MSNullable inUserData) {
    const APAudioAttachment &audioAttachment = *(APAudioAttachment *)inUserData;
    const MSNaluParts &naluParts = audioAttachment.audioSource->getNaluParts();
    
    ioData->mNumberBuffers = 1;
    ioData->mBuffers->mData = (void *)naluParts.dataRef();
    ioData->mBuffers->mDataByteSize = (UInt32)naluParts.dataSize();
    ioData->mBuffers->mNumberChannels = (UInt32)audioAttachment.audioParameters->channels;
    
    return noErr;
}
